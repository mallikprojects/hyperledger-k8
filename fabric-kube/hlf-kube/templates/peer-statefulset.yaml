{{- if .Values.peer.launchPods }}
{{- range $i, $org := $.Values.PeerOrgs }}
{{- range $peerIndex := until ($org.Template.Count | int) }}
{{- $peer := (printf "peer%s" ($peerIndex | toString)) }}
{{- $peerAddress := $.Values.useActualDomains | ternary (printf "%s.%s:7051" $peer $org.Domain) (printf "hlf-peer--%s--%s:7051" ($org.Name | lower) ($peer | lower)) }}
# peerAddress: {{ $peerAddress }}

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: hlf-peer--{{ $org.Name | lower }}--{{ $peer | lower }}
spec:
  replicas: 1
  serviceName: hlf-peer--{{ $org.Name | lower }}--{{ $peer | lower }}
  selector:
    matchLabels:
      app: hlf-peer--{{ $org.Name | lower }}--{{ $peer | lower }}
  volumeClaimTemplates:
  {{- if $.Values.peer.persistence.enabled }}
  - metadata:
      name: peer-disk
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: {{ $.Values.persistence.storageClass }}
      resources:
        requests:
          storage: {{ $.Values.peer.persistence.size }}
  {{- end }}
  {{- if $.Values.couchdb.persistence.enabled }}
  - metadata:
      name: couchdb-disk
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: {{ $.Values.persistence.storageClass }}
      resources:
        requests:
          storage: {{ $.Values.couchdb.persistence.size }}
  {{- end }}
  template:
    metadata:
      labels:
        name: hlf-peer 
        org: hlf-peer--{{ $org.Name | lower }}
        app: hlf-peer--{{ $org.Name | lower }}--{{ $peer | lower }}
    spec:
      volumes:
      {{- if not $.Values.peer.persistence.enabled }}
      - name: peer-disk
        emptyDir: {}
      {{- end }}
      {{- if not $.Values.couchdb.persistence.enabled }}
      - name: couchdb-disk
        emptyDir: {}
      {{- end }}
      - name: rsync-disk
        emptyDir: {}
      - name: dockersocket
        hostPath:
          path: /var/run/docker.sock
      {{- range $i, $org := $.Values.PeerOrgs }}
      - name: hlf-peer-org--{{ $org.Name | lower }}
        persistentVolumeClaim:
          claimName: hlf-peer-org--{{ $org.Name | lower }}
      - name: hlf-ca--{{ $org.Name | lower }}
        persistentVolumeClaim:
          claimName: hlf-ca--{{ $org.Name | lower }}
      {{- range $peerIndex := until ($org.Template.Count | int) }}
      {{- $peer := (printf "peer%s" ($peerIndex | toString)) }}

      - name: hlf-peer--{{ $org.Name | lower }}--{{ $peer | lower }}
        persistentVolumeClaim:
          claimName: hlf-peer--{{ $org.Name | lower }}--{{ $peer | lower }}

      {{- end }} {{- /* peers */ -}}{{""}}
      {{- end }} {{- /* peer orgs */ -}}{{""}}
      #- name: hlf-data
      #  persistentVolumeClaim:
      #    claimName: azurefile

      #- name: peer-tls
      #  secret:
      #    secretName: hlf-peer--{{ $org.Name | lower }}--{{ $peer | lower }}-tls
      #- name: peer-msp
      #  secret:
      #    secretName: hlf-peer--{{ $org.Name | lower }}--{{ $peer | lower }}-msp
      #    items:
      #    - key: cert.pem
      #      path: signcerts/cert.pem
      #    - key: key.pem
      #      path: keystore/key.pem
      #    - key: cacert.pem
      #      path: cacerts/cert.pem
      #    - key: tlscacert.pem
      #      path: tlscacerts/cert.pem
      #    - key: admincert.pem
      #      path: admincerts/cert.pem
      #- name: peer-admin-msp
      #  secret:
      #    secretName: hlf-peer--{{ $org.Name | lower }}--admin-msp
      #    items:
      #    - key: cert.pem
      #      path: signcerts/cert.pem
      #    - key: key.pem
      #      path: keystore/key.pem
      #    - key: cacert.pem
      #      path: cacerts/cert.pem
      #    - key: tlscacert.pem
      #      path: tlscacerts/cert.pem
      #    - key: admincert.pem
      #      path: admincerts/cert.pem
      # chaincodes
      {{- range $i, $chaincode := $.Values.network.chaincodes }}    
      - name: chaincode-{{ $chaincode.name | lower }}
        configMap:
          name: hlf-chaincode--{{ $chaincode.name | lower }}
      {{- end }}

      {{- if $.Values.hostAliases }}
      hostAliases:
      {{- range $i, $alias := $.Values.hostAliases }}
      - ip: {{ $alias.ip }}
        hostnames: {{ $alias.hostnames }}
      {{- end }}
      {{- end }}{{""}}

      containers:

      {{- if $.Values.backup.enabled }}

      # rsync-server container
      - name: rsync
        image: axiom/rsync-server:latest
        command: ["sh", "-c", "mkdir -p /data && sleep 30 && \
          {{- if $.Values.peer.backup.enabled }}
                               tar -czf /data/peer.tar -C /var/hyperledger/production ledgersData/ chaincodes/ && \
                               echo 'prepared peer data for backup' && \
          {{- end }}
          {{- if $.Values.couchdb.backup.enabled }}
                               tar -czf /data/couchdb.tar -C /opt/couchdb/data --exclude='lost+found' .  && \
                               echo 'prepared CouchDB data for backup' && \
          {{- end }}
                               touch /ready && \
                               /entrypoint.sh rsync_server"]
                               
        readinessProbe:
          exec:
            command: ["ls", "/ready"]

        volumeMounts:
        - mountPath: /var/hyperledger/production/
          name: peer-disk
        - mountPath: /opt/couchdb/data/
          name: couchdb-disk

        env:
        - name: ALLOW
          value: 0.0.0.0/0

      {{- else if $.Values.restore.enabled }}

      # rsync-server container
      - name: rsync
        image: axiom/rsync-server:latest
        command: ["sh", "-c", "/entrypoint.sh rsync_server"]
                               
        volumeMounts:
        - mountPath: /data/
          name: rsync-disk

        env:
        - name: ALLOW
          value: 0.0.0.0/0

      - name: shell
        image: debian:jessie
        command: ["sh", "-c", "echo 'waiting for file /data/ready..' && \
                               while [ ! -f /data/ready ]; do sleep 5; done && \
                               echo 'data is ready, proceeding..' && \
          {{- if $.Values.peer.restore.enabled }}
                               rm -rf /var/hyperledger/production/* && \
                               tar -xf /data/peer.tar -C /var/hyperledger/production/ && \
                               echo 'restored peer data from backup' && \
          {{- end }}
          {{- if $.Values.couchdb.restore.enabled }}
                               rm -rf /opt/couchdb/data/* && \
                               tar -xf /data/couchdb.tar -C /opt/couchdb/data/ && \
                               echo 'restored CouchDB data from backup' && \
          {{- end }}
                               echo 'ready to continue..' && \
                               while true; do sleep 60; done"]
                               
        volumeMounts:
        - mountPath: /var/hyperledger/production/
          name: peer-disk
        - mountPath: /opt/couchdb/data/
          name: couchdb-disk
        - mountPath: /data/
          name: rsync-disk

        env:
        - name: ALLOW
          value: 0.0.0.0/0

      {{- else }} {{- /* if backup/restore enabled */ -}}{{""}}

      # Peer container
      - name: peer
        image: hyperledger/fabric-peer:{{ $.Values.hyperledgerVersion }}
        command: ["sh", "-c", "peer node start"]

        volumeMounts:

              
        - mountPath: /hlf-peer-org--{{ $org.Name | lower }}
          name: hlf-peer-org--{{ $org.Name | lower }}
        - mountPath: /var/hyperledger/production/
          name: peer-disk
        - mountPath: /host/var/run/docker.sock
          name: dockersocket
        - mountPath: /etc/hyperledger/fabric/tls/
          name: hlf-peer--{{ $org.Name | lower }}--{{ $peer | lower }}
          subPath: tls

        - mountPath: /etc/hyperledger/fabric/msp/
          name: hlf-peer--{{ $org.Name | lower }}--{{ $peer | lower }}
          subPath: msp

        - mountPath: /etc/hyperledger/fabric/admin-msp/
          name: hlf-peer-org--{{ $org.Name | lower }}
          subPath: msp 
        #- mountPath: /etc/hyperledger/fabric/tls/
        #  name: peer-tls
        #- mountPath: /etc/hyperledger/fabric/msp/
        #  name: peer-msp
        #- mountPath: /etc/hyperledger/fabric/admin-msp/
        #  name: peer-admin-msp
        # - mountPath: /hl_config/channel/
        #   name: hlf-channels
        # chaincodes
        {{- range $i, $chaincode := $.Values.network.chaincodes }}    
        - mountPath: /chaincode/{{ $chaincode.name }}
          name: chaincode-{{ $chaincode.name | lower }}
        {{- end }}

        env:
        # TODO move configurable ones to configmaps
        - name: CORE_PEER_ID
          value: {{ $peer }}.{{ $org.Domain }}
        - name: CORE_PEER_ADDRESS
          value: {{ $peerAddress }}
        - name: CORE_PEER_LISTENADDRESS
          value: 0.0.0.0:7051
        - name: CORE_PEER_CHAINCODELISTENADDRESS
          value: 0.0.0.0:7052
        - name: CORE_PEER_GOSSIP_BOOTSTRAP
          value: >- 
        {{- range $peerIndexInner := until ($org.Template.Count | int) }}
        {{- $peer := (printf "peer%s" ($peerIndexInner | toString)) }}
        {{- $peerGossipAddress := $.Values.useActualDomains | ternary (printf "%s.%s:7051" $peer $org.Domain) (printf "hlf-peer--%s--%s:7051" ($org.Name | lower) ($peer | lower)) }}
              {{ $peerGossipAddress }}
        {{- end }} {{- /* Peers */ -}}{{""}}

        - name: CORE_PEER_GOSSIP_EXTERNALENDPOINT
          value: {{ $peerAddress }}
        - name: CORE_PEER_LOCALMSPID
          value: {{ $org.Name }}MSP

        - name: CORE_VM_ENDPOINT
          value: unix:///host/var/run/docker.sock
        - name: FABRIC_LOGGING_SPEC
          value: {{ $.Values.peer.logLevel }}
        - name: CORE_PEER_TLS_ENABLED
          value: {{ $.Values.tlsEnabled | quote }}
        - name: CORE_PEER_GOSSIP_USELEADERELECTION
          value: "true"
        - name: CORE_PEER_GOSSIP_ORGLEADER
          value: "false"
        - name: CORE_PEER_PROFILE_ENABLED
          value: "true"
        - name: CORE_PEER_ADDRESSAUTODETECT
          value: "true" # looks like absolutely necessary, o/w chaincode instantiate fails, no clue why
        - name: CORE_PEER_TLS_CERT_FILE
          value: /etc/hyperledger/fabric/tls/server.crt
        - name: CORE_PEER_TLS_KEY_FILE
          value: /etc/hyperledger/fabric/tls/server.key
        - name: CORE_PEER_TLS_ROOTCERT_FILE
          value: /etc/hyperledger/fabric/msp/tlscacerts/hlf-ca--{{ $org.Name | lower }}-7054.pem
        
        - name: CORE_CHAINCODE_LOGGING_LEVEL
          value: {{ $.Values.peer.chaincode.logging.level }}
        - name: CORE_CHAINCODE_LOGGING_SHIM
          value: {{ $.Values.peer.chaincode.logging.shim }}
        
        - name: CORE_LEDGER_STATE_STATEDATABASE
          value: CouchDB
        - name: CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS
          value: localhost:5984
        - name: CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME
          value: {{ $.Values.couchdb.userName | quote }}
        - name: CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD
          value: {{ $.Values.couchdb.password | quote }}
        
        - name: HFC_LOGGING
          value: '{"info":"console"}'
        - name: GRPC_VERBOSITY
          value: DEBUG
        - name: GRPC_TRACE
          value:  all
        
      # CouchDB container
      - name: couchdb
        image: hyperledger/fabric-couchdb:{{ $.Values.couchdb.version }}

        volumeMounts:
        - mountPath: /opt/couchdb/data/
          name: couchdb-disk
        
        env:
        - name: COUCHDB_USER
          value: {{ $.Values.couchdb.userName | quote }}
        - name: COUCHDB_PASSWORD
          value: {{ $.Values.couchdb.password | quote }}

      {{- end }} {{- /* if/else backup/restore enabled */ -}}{{""}}
---
{{- end }} {{- /* Peers */ -}}
{{- end }} {{- /* Orgs */ -}}
{{- end }} {{- /* if launchPods */ -}}